{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E8qaJg4zX81Z",
        "outputId": "bfd0bd8c-fd33-4e91-c44e-8549ec8b423c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: neattext in /usr/local/lib/python3.10/dist-packages (0.1.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Original Class Distribution:\n",
            " Emotion\n",
            "neutral       14715\n",
            "sadness       11887\n",
            "joy           11045\n",
            "worry          8459\n",
            "surprise       6249\n",
            "fear           5410\n",
            "happiness      5209\n",
            "anger          4407\n",
            "love           3842\n",
            "fun            1776\n",
            "relief         1526\n",
            "hate           1323\n",
            "disgust         856\n",
            "empty           827\n",
            "enthusiasm      759\n",
            "boredom         179\n",
            "shame           146\n",
            "Name: count, dtype: int64\n",
            "Filtered Class Distribution:\n",
            " Emotion\n",
            "neutral      14715\n",
            "sadness      11887\n",
            "joy          11045\n",
            "worry         8459\n",
            "surprise      6249\n",
            "fear          5410\n",
            "happiness     5209\n",
            "anger         4407\n",
            "love          3842\n",
            "fun           1776\n",
            "relief        1526\n",
            "hate          1323\n",
            "Name: count, dtype: int64\n",
            "Training and evaluating SVM on the filtered dataset...\n",
            "SVM Accuracy: 0.44\n",
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.68      0.45      0.54       896\n",
            "        fear       0.72      0.57      0.64      1055\n",
            "         fun       0.08      0.01      0.02       359\n",
            "   happiness       0.31      0.29      0.30      1083\n",
            "        hate       0.33      0.12      0.18       245\n",
            "         joy       0.50      0.59      0.54      2243\n",
            "        love       0.43      0.36      0.39       776\n",
            "     neutral       0.40      0.67      0.50      2895\n",
            "      relief       0.21      0.01      0.02       342\n",
            "     sadness       0.42      0.47      0.44      2371\n",
            "    surprise       0.48      0.25      0.33      1259\n",
            "       worry       0.28      0.19      0.23      1646\n",
            "\n",
            "    accuracy                           0.44     15170\n",
            "   macro avg       0.40      0.33      0.34     15170\n",
            "weighted avg       0.43      0.44      0.42     15170\n",
            "\n",
            "SVM model saved as svm_model.pkl\n",
            "\n",
            "Training and evaluating RandomForest on the filtered dataset...\n",
            "RandomForest Accuracy: 0.43\n",
            "RandomForest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.73      0.42      0.53       896\n",
            "        fear       0.81      0.58      0.68      1055\n",
            "         fun       0.15      0.02      0.04       359\n",
            "   happiness       0.28      0.19      0.23      1083\n",
            "        hate       0.19      0.06      0.09       245\n",
            "         joy       0.49      0.57      0.53      2243\n",
            "        love       0.38      0.35      0.36       776\n",
            "     neutral       0.37      0.72      0.49      2895\n",
            "      relief       0.08      0.01      0.02       342\n",
            "     sadness       0.41      0.45      0.43      2371\n",
            "    surprise       0.55      0.22      0.32      1259\n",
            "       worry       0.27      0.17      0.21      1646\n",
            "\n",
            "    accuracy                           0.43     15170\n",
            "   macro avg       0.39      0.31      0.33     15170\n",
            "weighted avg       0.43      0.43      0.40     15170\n",
            "\n",
            "RandomForest model saved as randomforest_model.pkl\n",
            "\n",
            "Training and evaluating GradientBoosting on the filtered dataset...\n",
            "GradientBoosting Accuracy: 0.38\n",
            "GradientBoosting Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.84      0.34      0.48       896\n",
            "        fear       0.84      0.43      0.57      1055\n",
            "         fun       0.12      0.03      0.05       359\n",
            "   happiness       0.33      0.17      0.22      1083\n",
            "        hate       0.20      0.14      0.16       245\n",
            "         joy       0.55      0.39      0.46      2243\n",
            "        love       0.36      0.35      0.36       776\n",
            "     neutral       0.28      0.85      0.43      2895\n",
            "      relief       0.07      0.01      0.02       342\n",
            "     sadness       0.52      0.32      0.40      2371\n",
            "    surprise       0.60      0.17      0.27      1259\n",
            "       worry       0.34      0.11      0.17      1646\n",
            "\n",
            "    accuracy                           0.38     15170\n",
            "   macro avg       0.42      0.28      0.30     15170\n",
            "weighted avg       0.46      0.38      0.36     15170\n",
            "\n",
            "GradientBoosting model saved as gradientboosting_model.pkl\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c6af2819-c6e6-4ebc-8603-20b938f3fd1a\", \"svm_model.pkl\", 18725713)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_37da0b86-c7ca-4773-a2f7-39a1e26bc459\", \"randomforest_model.pkl\", 1006792018)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_89a3dbfc-7f13-48a1-9b1c-8c52f2fe79e6\", \"gradientboosting_model.pkl\", 3393798)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install scikit-learn neattext\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn import metrics\n",
        "import joblib\n",
        "import neattext.functions as nfx\n",
        "import re\n",
        "\n",
        "\n",
        "def load_csv_with_fallback(filename):\n",
        "    try:\n",
        "        return pd.read_csv(filename, encoding='utf-8')\n",
        "    except UnicodeDecodeError:\n",
        "        return pd.read_csv(filename, encoding='ISO-8859-1')\n",
        "\n",
        "# Load datasets\n",
        "mental_tweet_df = pd.read_csv('mental_tweet.csv')\n",
        "conversation_df = load_csv_with_fallback('Merged_Conversation.csv')\n",
        "\n",
        "# Clean the text\n",
        "def clean_text(text):\n",
        "    text = nfx.remove_userhandles(text)  # Remove user handles\n",
        "    text = nfx.remove_stopwords(text)    # Remove stop words\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)  # Remove URLs\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    return text\n",
        "\n",
        "# Apply cleaning function to the text columns\n",
        "mental_tweet_df['Clean_Text'] = mental_tweet_df['Text'].apply(clean_text)\n",
        "conversation_df['Clean_Text'] = conversation_df['Questions'].apply(clean_text)\n",
        "\n",
        "# Label data as 'neutral' or any appropriate placeholder\n",
        "conversation_df['Emotion'] = 'neutral'\n",
        "\n",
        "# Combine all data\n",
        "combined_df = pd.concat([\n",
        "    mental_tweet_df[['Clean_Text', 'Emotion']],\n",
        "    conversation_df[['Clean_Text', 'Emotion']]\n",
        "])\n",
        "\n",
        "# Check for and handle missing values\n",
        "combined_df.dropna(subset=['Clean_Text', 'Emotion'], inplace=True)\n",
        "\n",
        "# Print original data distribution\n",
        "print(\"Original Class Distribution:\\n\", combined_df['Emotion'].value_counts())\n",
        "\n",
        "# Remove minority labels below a specified threshold count\n",
        "threshold_count = 1000  # Define the minimum number of samples required for a class to be retained\n",
        "filtered_df = combined_df[combined_df['Emotion'].map(combined_df['Emotion'].value_counts()) >= threshold_count]\n",
        "\n",
        "# Print data distribution after removing minority labels\n",
        "print(\"Filtered Class Distribution:\\n\", filtered_df['Emotion'].value_counts())\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = filtered_df['Clean_Text']\n",
        "y = filtered_df['Emotion']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define pipelines with different models\n",
        "pipelines = {\n",
        "    'SVM': Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(stop_words='english', max_features=10000, ngram_range=(1, 2))),\n",
        "        ('clf', SVC(kernel='linear', C=1, probability=True))\n",
        "    ]),\n",
        "    'RandomForest': Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(stop_words='english')),\n",
        "        ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "    ]),\n",
        "    'GradientBoosting': Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(stop_words='english')),\n",
        "        ('clf', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Train, evaluate, and save each model\n",
        "for model_name, pipeline in pipelines.items():\n",
        "    print(f\"Training and evaluating {model_name} on the filtered dataset...\")\n",
        "\n",
        "    # Train the model\n",
        "    pipeline.fit(x_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = pipeline.predict(x_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "    print(f\"{model_name} Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"{model_name} Classification Report:\\n{metrics.classification_report(y_test, y_pred)}\")\n",
        "\n",
        "    # Save the trained model\n",
        "    joblib.dump(pipeline, f'{model_name.lower()}_model.pkl')\n",
        "    print(f\"{model_name} model saved as {model_name.lower()}_model.pkl\\n\")\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "files.download('svm_model.pkl')\n",
        "files.download('randomforest_model.pkl')\n",
        "files.download('gradientboosting_model.pkl')\n"
      ]
    }
  ]
}